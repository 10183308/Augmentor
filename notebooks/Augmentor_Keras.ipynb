{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training a Neural Network using Augmentor and Keras\n",
    "\n",
    "In this notebook, we will train a simple convolutional neural network on the MNIST dataset using Augmentor to augment images on the fly using a generator.\n",
    "\n",
    "## Import Required Libraries\n",
    "\n",
    "We start by making a number of imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import Augmentor\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define a Convolutional Neural Network\n",
    "\n",
    "Once the libraries have been imported, we define a small convolutional neural network. See the Keras documentation for details of this network: <https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py> \n",
    "\n",
    "It is a three layer deep neural network, consisting of 2 convolutional layers and a fully connected layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Once a network has been defined, you can compile it so that the model is ready to be trained with data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You can view a summary of the network using the `summary()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Use Augmentor to Scan Directory for Data\n",
    "\n",
    "Now we will use Augmentor to scan a directory containing our data that we will eventually feed into the neural network in order to train it. \n",
    "\n",
    "When you point a pipeline to a directory, it will scan each subdirectory and treat each subdirectory as a class for your machine learning problem. \n",
    "\n",
    "For example, within the directory `mnist`, there are subdirectories for each digit:\n",
    "\n",
    "```\n",
    "mnist/\n",
    "├── 0/\n",
    "│   ├── 0001.png\n",
    "│   ├── 0002.png\n",
    "│   ├── ...\n",
    "│   └── 5985.png\n",
    "├── 1/\n",
    "│   ├── 0001.png\n",
    "│   ├── 0002.png\n",
    "│   ├── ...\n",
    "│   └── 6101.png\n",
    "├── 2/\n",
    "│   ├── 0000.png\n",
    "│   ├── 0001.png\n",
    "│   ├── ...\n",
    "│   └── 5801.png\n",
    "│ ...\n",
    "├── 9/\n",
    "│   ├── 0001.png\n",
    "│   ├── 0002.png\n",
    "│   ├── ...\n",
    "│   └── 6001.png\n",
    "└\n",
    "```\n",
    "\n",
    "The directory `0` contains all the images corresponding to the 0 class.\n",
    "\n",
    "To do this, we instantiate a pipeline object in the `mnist` parent directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 60000 image(s) found.\n",
      "Output directory set to /home/marcus/Documents/mnist/train/output."
     ]
    }
   ],
   "source": [
    "p = Augmentor.Pipeline(\"/home/marcus/Documents/mnist/train/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Add Operations to the Pipeline\n",
    "\n",
    "Now that a pipeline object `p` has been created, we can add operations to the pipeline. Below we add several simple  operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "p.flip_top_bottom(probability=0.1)\n",
    "p.rotate(probability=0.3, max_left_rotation=5, max_right_rotation=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You can view the status of pipeline using the `status()` function, which shows information regarding the number of classes in the pipeline, the number of images, and what operations have been added to the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operations: 2\n",
      "\t0: Flip (top_bottom_left_right=TOP_BOTTOM probability=0.1 )\n",
      "\t1: RotateRange (max_right_rotation=5.0 max_left_rotation=-5.0 probability=0.3 )\n",
      "Images: 60000\n",
      "Classes: 10\n",
      "\tClass index: 0 Class label: 0 \n",
      "\tClass index: 1 Class label: 1 \n",
      "\tClass index: 2 Class label: 2 \n",
      "\tClass index: 3 Class label: 3 \n",
      "\tClass index: 4 Class label: 4 \n",
      "\tClass index: 5 Class label: 5 \n",
      "\tClass index: 6 Class label: 6 \n",
      "\tClass index: 7 Class label: 7 \n",
      "\tClass index: 8 Class label: 8 \n",
      "\tClass index: 9 Class label: 9 \n",
      "Dimensions: 1\n",
      "\tWidth: 28 Height: 28\n",
      "Formats: 1\n",
      "\t PNG\n",
      "\n",
      "You can remove operations using the appropriate index and the remove_operation(index) function.\n"
     ]
    }
   ],
   "source": [
    "p.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Creating a Generator\n",
    "\n",
    "A generator will create images indefinitely, and we can use this generator as input into the model created above. The generator is created with a user-defined batch size, which we define here in a variable named `batch_size`. This is used later to define number of steps per epoch, so it is best to keep it stored as a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "g = p.keras_generator(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The generator can now be used to created augmented data. In Python, generators are invoked using the `next()` function - the Augmentor generators will return images indefinitely, and so `next()` can be called as often as required. \n",
    "\n",
    "You can view the output of generator manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "images, labels = next(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Images, and their labels, are returned in batches of the size defined above by `batch_size`. The `image_batch` variable is a tuple, containing the augmentented images and their corresponding labels.\n",
    "\n",
    "To see the label of the first image returned by the generator you can use the array's index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or preview the images using Matplotlib (the image should be a 9, according to the label information above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0ERfiCo/weTyS/WCWBAywAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f677c63df50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].reshape(28, 28), cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Network\n",
    "\n",
    "We train the network by passing the generator, `g`, to the model's fit function. In Keras, if a generator is used we used the `fit_generator()` function as opposed to the standard `fit()` function. Also, the steps per epoch should roughly equal the total number of images in your dataset divided by the `batch_size`.\n",
    "\n",
    "Training the network over 5 epochs, we get the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "468/468 [==============================] - 28s 60ms/step - loss: 0.4813 - acc: 0.8472\n",
      "Epoch 2/5\n",
      "468/468 [==============================] - 28s 59ms/step - loss: 0.1988 - acc: 0.9403\n",
      "Epoch 3/5\n",
      "468/468 [==============================] - 27s 58ms/step - loss: 0.1637 - acc: 0.9516\n",
      "Epoch 4/5\n",
      "468/468 [==============================] - 27s 58ms/step - loss: 0.1407 - acc: 0.9583\n",
      "Epoch 5/5\n",
      "468/468 [==============================] - 27s 58ms/step - loss: 0.1232 - acc: 0.9631\n"
     ]
    }
   ],
   "source": [
    "h = model.fit_generator(g, steps_per_epoch=len(p.augmentor_images)/batch_size, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Summary\n",
    "\n",
    "Using Augmentor with Keras means only that you need to create a generator when you are finished creating your pipeline. This has the advantage that no images need to be saved to disk and are augmented on the fly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
