{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Neural Network using Augmentor and Keras\n",
    "\n",
    "In this notebook, we will train a simple convolutional neural network on the MNIST dataset using Augmentor to augment images on the fly using a generator.\n",
    "\n",
    "## Import Required Libraries\n",
    "\n",
    "We start by making a number of imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import Augmentor\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Convolutional Neural Network\n",
    "\n",
    "Once the libraries have been imported, we define a small convolutional neural network. See the Keras documentation for details of this network: <https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py> \n",
    "\n",
    "It is a three layer deep neural network, consisting of 2 convolutional layers and a fully connected layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a network has been defined, you can compile it so that the model is ready to be trained with data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view a summary of the network using the `summary()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Augmentor to Scan Directory for Data\n",
    "\n",
    "Now we will use Augmentor to scan a directory containing our data that we will eventually feed into the neural network in order to train it. \n",
    "\n",
    "When you point a pipeline to a directory, it will scan each subdirectory and treat each subdirectory as a class for your machine learning problem. \n",
    "\n",
    "For example, within the directory `mnist`, there are subdirectories for each digit:\n",
    "\n",
    "```\n",
    "mnist/\n",
    "├── 0/\n",
    "│   ├── 0001.png\n",
    "│   ├── 0002.png\n",
    "│   ├── ...\n",
    "│   └── 5985.png\n",
    "├── 1/\n",
    "│   ├── 0001.png\n",
    "│   ├── 0002.png\n",
    "│   ├── ...\n",
    "│   └── 6101.png\n",
    "├── 2/\n",
    "│   ├── 0000.png\n",
    "│   ├── 0001.png\n",
    "│   ├── ...\n",
    "│   └── 5801.png\n",
    "│ ...\n",
    "├── 9/\n",
    "│   ├── 0001.png\n",
    "│   ├── 0002.png\n",
    "│   ├── ...\n",
    "│   └── 6001.png\n",
    "└\n",
    "```\n",
    "\n",
    "The directory `0` contains all the images corresponding to the 0 class.\n",
    "\n",
    "To do this, we instantiate a pipeline object in the `mnist` parent directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-03-23 14:59:00--  https://rawgit.com/myleott/mnist_png/master/mnist_png.tar.gz\n",
      "Resolving rawgit.com (rawgit.com)... 104.18.63.176, 104.18.62.176, 2400:cb00:2048:1::6812:3eb0, ...\n",
      "Connecting to rawgit.com (rawgit.com)|104.18.63.176|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://raw.githubusercontent.com/myleott/mnist_png/master/mnist_png.tar.gz [following]\n",
      "--2018-03-23 14:59:01--  https://raw.githubusercontent.com/myleott/mnist_png/master/mnist_png.tar.gz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.112.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.112.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 15683414 (15M) [application/octet-stream]\n",
      "Saving to: ‘mnist_png.tar.gz’\n",
      "\n",
      "100%[======================================>] 15,683,414  8.98MB/s   in 1.7s   \n",
      "\n",
      "2018-03-23 14:59:03 (8.98 MB/s) - ‘mnist_png.tar.gz’ saved [15683414/15683414]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://rawgit.com/myleott/mnist_png/master/mnist_png.tar.gz\n",
    "!tar -xf mnist_png.tar.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 60000 image(s) found.\n",
      "Output directory set to mnist_png/training/output."
     ]
    }
   ],
   "source": [
    "p = Augmentor.Pipeline(\"mnist_png/training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Operations to the Pipeline\n",
    "\n",
    "Now that a pipeline object `p` has been created, we can add operations to the pipeline. Below we add several simple  operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.flip_top_bottom(probability=0.1)\n",
    "p.rotate(probability=0.3, max_left_rotation=5, max_right_rotation=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view the status of pipeline using the `status()` function, which shows information regarding the number of classes in the pipeline, the number of images, and what operations have been added to the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operations: 2\n",
      "\t0: Flip (top_bottom_left_right=TOP_BOTTOM probability=0.1 )\n",
      "\t1: RotateRange (max_right_rotation=5.0 max_left_rotation=-5.0 probability=0.3 )\n",
      "Images: 60000\n",
      "Classes: 10\n",
      "\tClass index: 0 Class label: 0 \n",
      "\tClass index: 1 Class label: 1 \n",
      "\tClass index: 2 Class label: 2 \n",
      "\tClass index: 3 Class label: 3 \n",
      "\tClass index: 4 Class label: 4 \n",
      "\tClass index: 5 Class label: 5 \n",
      "\tClass index: 6 Class label: 6 \n",
      "\tClass index: 7 Class label: 7 \n",
      "\tClass index: 8 Class label: 8 \n",
      "\tClass index: 9 Class label: 9 \n",
      "Dimensions: 1\n",
      "\tWidth: 28 Height: 28\n",
      "Formats: 1\n",
      "\t PNG\n",
      "\n",
      "You can remove operations using the appropriate index and the remove_operation(index) function.\n"
     ]
    }
   ],
   "source": [
    "p.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Generator\n",
    "\n",
    "A generator will create images indefinitely, and we can use this generator as input into the model created above. The generator is created with a user-defined batch size, which we define here in a variable named `batch_size`. This is used later to define number of steps per epoch, so it is best to keep it stored as a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "g = p.keras_generator(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator can now be used to created augmented data. In Python, generators are invoked using the `next()` function - the Augmentor generators will return images indefinitely, and so `next()` can be called as often as required. \n",
    "\n",
    "You can view the output of generator manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images, and their labels, are returned in batches of the size defined above by `batch_size`. The `image_batch` variable is a tuple, containing the augmentented images and their corresponding labels.\n",
    "\n",
    "To see the label of the first image returned by the generator you can use the array's index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or preview the images using Matplotlib (the image should be a 1, according to the label information above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwy8V9f/yOA4RKrfeiwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4f5b2f8550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].reshape(28, 28), cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Network\n",
    "\n",
    "We train the network by passing the generator, `g`, to the model's fit function. In Keras, if a generator is used we used the `fit_generator()` function as opposed to the standard `fit()` function. Also, the steps per epoch should roughly equal the total number of images in your dataset divided by the `batch_size`.\n",
    "\n",
    "Training the network over 5 epochs, we get the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "468/468 [==============================] - 37s 79ms/step - loss: 0.4748 - acc: 0.8508\n",
      "Epoch 2/5\n",
      "468/468 [==============================] - 28s 61ms/step - loss: 0.1966 - acc: 0.9409\n",
      "Epoch 3/5\n",
      "468/468 [==============================] - 28s 61ms/step - loss: 0.1589 - acc: 0.9523\n",
      "Epoch 4/5\n",
      "468/468 [==============================] - 27s 59ms/step - loss: 0.1386 - acc: 0.9586\n",
      "Epoch 5/5\n",
      "468/468 [==============================] - 27s 59ms/step - loss: 0.1210 - acc: 0.9640\n"
     ]
    }
   ],
   "source": [
    "h = model.fit_generator(g, steps_per_epoch=len(p.augmentor_images)/batch_size, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Using Augmentor with Keras means only that you need to create a generator when you are finished creating your pipeline. This has the advantage that no images need to be saved to disk and are augmented on the fly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
