{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training a Neural Network using Augmentor and Keras\n",
    "\n",
    "In this notebook, we will train a simple convolutional neural network on the MNIST dataset using Augmentor to augment images on the fly using a generator.\n",
    "\n",
    "## Import Required Libraries\n",
    "\n",
    "We start by making a number of imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import Augmentor\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define a Convolutional Neural Network\n",
    "\n",
    "Once the libraries have been imported, we define a small convolutional neural network. See the Keras documentation for details of this network: <https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py> \n",
    "\n",
    "It is a three layer deep neural network, consisting of 2 convolutional layers and a fully connected layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Once a network has been defined, you can compile it so that the model is ready to be trained with data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You can view a summary of the network using the `summary()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Use Augmentor to Scan Directory for Data\n",
    "\n",
    "Now we will use Augmentor to scan a directory containing our data that we will eventually feed into the neural network in order to train it. \n",
    "\n",
    "When you point a pipeline to a directory, it will scan each subdirectory and treat each subdirectory as a class for your machine learning problem. \n",
    "\n",
    "For example, within the directory `mnist`, there are subdirectories for each digit:\n",
    "\n",
    "```\n",
    "mnist/\n",
    "├── 0/\n",
    "│   ├── 0001.png\n",
    "│   ├── 0002.png\n",
    "│   ├── ...\n",
    "│   └── 5985.png\n",
    "├── 1/\n",
    "│   ├── 0001.png\n",
    "│   ├── 0002.png\n",
    "│   ├── ...\n",
    "│   └── 6101.png\n",
    "├── 2/\n",
    "│   ├── 0000.png\n",
    "│   ├── 0001.png\n",
    "│   ├── ...\n",
    "│   └── 5801.png\n",
    "│ ...\n",
    "├── 9/\n",
    "│   ├── 0001.png\n",
    "│   ├── 0002.png\n",
    "│   ├── ...\n",
    "│   └── 6001.png\n",
    "└\n",
    "```\n",
    "\n",
    "The directory `0` contains all the images corresponding to the 0 class.\n",
    "\n",
    "To do this, we instantiate a pipeline object in the `mnist` parent directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 60000 image(s) found.\n",
      "Output directory set to /home/marcus/Documents/mnist/train/output."
     ]
    }
   ],
   "source": [
    "p = Augmentor.Pipeline(\"/home/marcus/Documents/mnist/train/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Add Operations to the Pipeline\n",
    "\n",
    "Now that a pipeline object `p` has been created, we can add operations to the pipeline. Below we add several simple  operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "p.flip_top_bottom(probability=0.1)\n",
    "p.rotate(probability=0.3, max_left_rotation=5, max_right_rotation=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You can view the status of pipeline using the `status()` function, which shows information regarding the number of classes in the pipeline, the number of images, and what operations have been added to the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operations: 2\n",
      "\t0: Flip (top_bottom_left_right=TOP_BOTTOM probability=0.1 )\n",
      "\t1: RotateRange (max_right_rotation=5.0 max_left_rotation=-5.0 probability=0.3 )\n",
      "Images: 60000\n",
      "Classes: 10\n",
      "\tClass index: 0 Class label: 0 \n",
      "\tClass index: 1 Class label: 1 \n",
      "\tClass index: 2 Class label: 2 \n",
      "\tClass index: 3 Class label: 3 \n",
      "\tClass index: 4 Class label: 4 \n",
      "\tClass index: 5 Class label: 5 \n",
      "\tClass index: 6 Class label: 6 \n",
      "\tClass index: 7 Class label: 7 \n",
      "\tClass index: 8 Class label: 8 \n",
      "\tClass index: 9 Class label: 9 \n",
      "Dimensions: 1\n",
      "\tWidth: 28 Height: 28\n",
      "Formats: 1\n",
      "\t PNG\n",
      "\n",
      "You can remove operations using the appropriate index and the remove_operation(index) function.\n"
     ]
    }
   ],
   "source": [
    "p.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Creating a Generator\n",
    "\n",
    "A generator will create images indefinitely, and we can use this generator as input into the model created above. The generator is created with a user-defined batch size, which we define here in a variable named `batch_size`. This is used later to define number of steps per epoch, so it is best to keep it stored as a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "g = p.keras_generator(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The generator can now be used to created augmented data. In Python, generators are invoked using the `next()` function - the Augmentor generators will return images indefinitely, and so `next()` can be called as often as required. \n",
    "\n",
    "You can view the output of generator manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "images, labels = next(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Images, and their labels, are returned in batches of the size defined above by `batch_size`. The `image_batch` variable is a tuple, containing the augmentented images and their corresponding labels.\n",
    "\n",
    "To see the label of the first image returned by the generator you can use the array's index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or preview the images using Matplotlib (the image should be a 4, according to the label information above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npAg/kBThB5Ii/EBSfwLa5ms7tuUZmgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5fefe12750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].reshape(28, 28), cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Network\n",
    "\n",
    "We train the network by passing the generator, `g`, to the model's fit function. In Keras, if a generator is used we used the `fit_generator()` function as opposed to the standard `fit()` function. Also, the steps per epoch should roughly equal the total number of images in your dataset divided by the `batch_size`.\n",
    "\n",
    "Training the network over 5 epochs, we get the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "468/468 [==============================] - 28s 60ms/step - loss: 0.4878 - acc: 0.8472\n",
      "Epoch 2/5\n",
      "468/468 [==============================] - 27s 58ms/step - loss: 0.1998 - acc: 0.9401\n",
      "Epoch 3/5\n",
      "468/468 [==============================] - 27s 57ms/step - loss: 0.1592 - acc: 0.9505\n",
      "Epoch 4/5\n",
      "468/468 [==============================] - 27s 57ms/step - loss: 0.1355 - acc: 0.9591\n",
      "Epoch 5/5\n",
      "468/468 [==============================] - 27s 59ms/step - loss: 0.1222 - acc: 0.9636\n"
     ]
    }
   ],
   "source": [
    "h = model.fit_generator(g, steps_per_epoch=len(p.augmentor_images)/batch_size, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Summary\n",
    "\n",
    "Using Augmentor with Keras means only that you need to create a generator when you are finished creating your pipeline. This has the advantage that no images need to be saved to disk and are augmented on the fly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
