{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training a Neural Network using Augmentor and Keras\n",
    "\n",
    "In this notebook, we will train a simple convolutional neural network on the MNIST dataset using Augmentor to augment images on the fly using a generator.\n",
    "\n",
    "## Import Required Libraries\n",
    "\n",
    "We start by making a number of imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import Augmentor\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Convolutional Neural Network\n",
    "\n",
    "Once the libraries have been imported, we define a small convolutional neural network. See the Keras documentation for details of this network: <https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py> \n",
    "\n",
    "It is a three layer deep neural network, consisting of 2 convolutional layers and a fully connected layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a network has been defined, you can compile it so that the model is ready to be trained with data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view a summary of the network using the `summary()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Augmentor to Scan Directory for Data\n",
    "\n",
    "Now we will use Augmentor to scan a directory containing our data that we will eventually feed into the neural network in order to train it. \n",
    "\n",
    "When you point a pipeline to a directory, it will scan each subdirectory and treat each subdirectory as a class for your machine learning problem. \n",
    "\n",
    "For example, within the directory `mnist`, there are subdirectories for each digit:\n",
    "\n",
    "```\n",
    "mnist/\n",
    "├── 0/\n",
    "│   ├── 0001.png\n",
    "│   ├── 0002.png\n",
    "│   ├── ...\n",
    "│   └── 5985.png\n",
    "├── 1/\n",
    "│   ├── 0001.png\n",
    "│   ├── 0002.png\n",
    "│   ├── ...\n",
    "│   └── 6101.png\n",
    "├── 2/\n",
    "│   ├── 0000.png\n",
    "│   ├── 0001.png\n",
    "│   ├── ...\n",
    "│   └── 5801.png\n",
    "│ ...\n",
    "├── 9/\n",
    "│   ├── 0001.png\n",
    "│   ├── 0002.png\n",
    "│   ├── ...\n",
    "│   └── 6001.png\n",
    "└\n",
    "```\n",
    "\n",
    "The directory `0` contains all the images corresponding to the 0 class.\n",
    "\n",
    "To do this, we instantiate a pipeline object in the `mnist` parent directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-03-03 09:38:38--  https://rawgit.com/myleott/mnist_png/master/mnist_png.tar.gz\n",
      "Resolving rawgit.com (rawgit.com)... 104.18.63.176, 104.18.62.176, 2400:cb00:2048:1::6812:3eb0, ...\n",
      "Connecting to rawgit.com (rawgit.com)|104.18.63.176|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://raw.githubusercontent.com/myleott/mnist_png/master/mnist_png.tar.gz [following]\n",
      "--2018-03-03 09:38:38--  https://raw.githubusercontent.com/myleott/mnist_png/master/mnist_png.tar.gz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.192.133, 151.101.128.133, 151.101.64.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.192.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 15683414 (15M) [application/octet-stream]\n",
      "Saving to: ‘mnist_png.tar.gz’\n",
      "\n",
      "mnist_png.tar.gz    100%[===================>]  14.96M  16.7MB/s    in 0.9s    \n",
      "\n",
      "2018-03-03 09:38:39 (16.7 MB/s) - ‘mnist_png.tar.gz’ saved [15683414/15683414]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://rawgit.com/myleott/mnist_png/master/mnist_png.tar.gz\n",
    "!tar -xf mnist_png.tar.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 60000 image(s) found.\n",
      "Output directory set to mnist_png/training/output."
     ]
    }
   ],
   "source": [
    "p = Augmentor.Pipeline(\"mnist_png/training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Operations to the Pipeline\n",
    "\n",
    "Now that a pipeline object `p` has been created, we can add operations to the pipeline. Below we add several simple  operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.flip_top_bottom(probability=0.1)\n",
    "p.rotate(probability=0.3, max_left_rotation=5, max_right_rotation=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view the status of pipeline using the `status()` function, which shows information regarding the number of classes in the pipeline, the number of images, and what operations have been added to the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operations: 2\n",
      "\t0: Flip (probability=0.1 top_bottom_left_right=TOP_BOTTOM )\n",
      "\t1: RotateRange (probability=0.3 max_left_rotation=-5 max_right_rotation=5 )\n",
      "Images: 60000\n",
      "Classes: 10\n",
      "\tClass index: 0 Class label: 0 \n",
      "\tClass index: 1 Class label: 1 \n",
      "\tClass index: 2 Class label: 2 \n",
      "\tClass index: 3 Class label: 3 \n",
      "\tClass index: 4 Class label: 4 \n",
      "\tClass index: 5 Class label: 5 \n",
      "\tClass index: 6 Class label: 6 \n",
      "\tClass index: 7 Class label: 7 \n",
      "\tClass index: 8 Class label: 8 \n",
      "\tClass index: 9 Class label: 9 \n",
      "Dimensions: 1\n",
      "\tWidth: 28 Height: 28\n",
      "Formats: 1\n",
      "\t PNG\n",
      "\n",
      "You can remove operations using the appropriate index and the remove_operation(index) function.\n"
     ]
    }
   ],
   "source": [
    "p.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Generator\n",
    "\n",
    "A generator will create images indefinitely, and we can use this generator as input into the model created above. The generator is created with a user-defined batch size, which we define here in a variable named `batch_size`. This is used later to define number of steps per epoch, so it is best to keep it stored as a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "g = p.keras_generator(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator can now be used to created augmented data. In Python, generators are invoked using the `next()` function - the Augmentor generators will return images indefinitely, and so `next()` can be called as often as required. \n",
    "\n",
    "You can view the output of generator manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images, and their labels, are returned in batches of the size defined above by `batch_size`. The `image_batch` variable is a tuple, containing the augmentented images and their corresponding labels.\n",
    "\n",
    "To see the label of the first image returned by the generator you can use the array's index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or preview the images using Matplotlib (the image should be a 4, according to the label information above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2786314940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].reshape(28, 28), cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Network\n",
    "\n",
    "We train the network by passing the generator, `g`, to the model's fit function. In Keras, if a generator is used we used the `fit_generator()` function as opposed to the standard `fit()` function. Also, the steps per epoch should roughly equal the total number of images in your dataset divided by the `batch_size`.\n",
    "\n",
    "Training the network over 5 epochs, we get the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "368/468 [======================>.......] - ETA: 9s - loss: 0.4351 - acc: 0.8631"
     ]
    }
   ],
   "source": [
    "h = model.fit_generator(g, steps_per_epoch=len(p.augmentor_images)/batch_size, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Using Augmentor with Keras means only that you need to create a generator when you are finished creating your pipeline. This has the advantage that no images need to be saved to disk and are augmented on the fly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
